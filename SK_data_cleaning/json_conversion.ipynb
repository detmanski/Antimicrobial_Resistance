{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kronh\\AppData\\Local\\Temp\\ipykernel_18208\\2426911453.py:12: SADeprecationWarning: The AutomapBase.prepare.reflect parameter is deprecated and will be removed in a future release.  Reflection is enabled when AutomapBase.prepare.autoload_with is passed.\n",
      "  Base.prepare(engine, reflect=True)\n"
     ]
    }
   ],
   "source": [
    "## Database Setup\n",
    "# Establishes the base filepath to find the database\n",
    "## NOTE: This will be different for each computer\n",
    "filepath = \"C:/Users/kronh/OneDrive/Documents/UofTCoding_bootcamp/project_3_data\"\n",
    "\n",
    "# Create engine using the 'amr.sqlite' database file\n",
    "engine = create_engine(f\"sqlite:///{filepath}/database/amr.sqlite\")\n",
    "\n",
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# Save references to the tables\n",
    "Regions = Base.classes.regions\n",
    "Countries = Base.classes.countries\n",
    "SpendingPop = Base.classes.spending_pop\n",
    "AMR_data = Base.classes.amr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a session\n",
    "session = Session(engine)\n",
    "\n",
    "# Query the database - grab all data from each table\n",
    "country_data = session.query(Countries).all()\n",
    "region_data = session.query(Regions).all()\n",
    "spending_pop_data = session.query(SpendingPop).all()\n",
    "amr_data = session.query(AMR_data).all()\n",
    "\n",
    "# Close the session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the data\n",
    "\n",
    "# Turn Countries into a list of dictionaries\n",
    "countries = []\n",
    "for item in country_data:\n",
    "    row_dict = {}\n",
    "    row_dict['id'] = item.id\n",
    "    row_dict['region_id'] = item.region_id\n",
    "    row_dict['country'] = item.country\n",
    "    countries.append(row_dict)\n",
    "\n",
    "# Turn Regions into a list of dictionaries\n",
    "regions = []\n",
    "for item in region_data:\n",
    "    row_dict = {}\n",
    "    row_dict['id'] = item.id\n",
    "    row_dict['region'] = item.region\n",
    "    regions.append(row_dict)\n",
    "\n",
    "# Turn Health Spending into a list of dictionaries\n",
    "spending_pop = []\n",
    "for item in spending_pop_data:\n",
    "    row_dict = {}\n",
    "    row_dict['id'] = item.id\n",
    "    row_dict['country_id'] = item.country_id\n",
    "    row_dict['region_id'] = item.region_id\n",
    "    row_dict['country'] = item.country\n",
    "    row_dict['code'] = item.code\n",
    "    row_dict['income'] = item.income\n",
    "    row_dict['year'] = item.year\n",
    "    row_dict['health_spending_mil_USD'] = item.health_spending_mil_USD\n",
    "    row_dict['population_thousands'] = item.population_thousands\n",
    "    row_dict['health_spending_per_capita_USD'] = item.health_spending_per_capita_USD\n",
    "    spending_pop.append(row_dict)\n",
    "\n",
    "# Turn Health Spending into a list of dictionaries\n",
    "amr = []\n",
    "for item in amr_data:\n",
    "    row_dict = {}\n",
    "    row_dict['id'] = item.id\n",
    "    row_dict['region_id'] = item.region_id\n",
    "    row_dict['measure_id'] = item.measure_id\n",
    "    row_dict['measure_name'] = item.measure_name\n",
    "    row_dict['location_id'] = item.location_id\n",
    "    row_dict['location_name'] = item.location_name\n",
    "    row_dict['sex_id'] = item.sex_id\n",
    "    row_dict['sex_name'] = item.sex_name\n",
    "    row_dict['age_group_id'] = item.age_group_id\n",
    "    row_dict['age_group_name'] = item.age_group_name\n",
    "    row_dict['cause_id'] = item.cause_id\n",
    "    row_dict['cause_name'] = item.cause_name\n",
    "    row_dict['year_id'] = item.year_id\n",
    "    row_dict['metric_id'] = item.metric_id\n",
    "    row_dict['metric_name'] = item.metric_name\n",
    "    row_dict['infectious_syndrome'] = item.infectious_syndrome\n",
    "    row_dict['pathogen'] = item.pathogen\n",
    "    row_dict['antibiotic_class'] = item.antibiotic_class\n",
    "    row_dict['counterfactual'] = item.counterfactual\n",
    "    row_dict['val'] = item.val\n",
    "    row_dict['upper'] = item.upper\n",
    "    row_dict['lower'] = item.lower\n",
    "    amr.append(row_dict)\n",
    "\n",
    "# Make a dictionary to hold all tables and add each list of dictionaries to the main dictionary\n",
    "all_data = {}\n",
    "all_data['countries'] = countries\n",
    "all_data['regions'] = regions\n",
    "all_data['spending_population'] = spending_pop\n",
    "all_data['AMR_data'] = amr\n",
    "\n",
    "## Make individual dictionaries for each dataset\n",
    "country_dict = {}\n",
    "country_dict['countries'] = countries\n",
    "\n",
    "region_dict = {}\n",
    "region_dict['regions'] = regions\n",
    "\n",
    "spending_dict = {}\n",
    "spending_dict['spending_population'] = spending_pop\n",
    "\n",
    "amr_dict = {}\n",
    "amr_dict['countries'] = amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the massive dictionary to a json file\n",
    "with open(f\"{filepath}/data_json/all_data.json\", \"w\") as outfile:\n",
    "    json.dump(all_data, outfile, indent=4, separators=(\", \", \": \"))\n",
    "\n",
    "# Convert each individual dataset to a json file\n",
    "with open(f\"{filepath}/data_json/countries.json\", \"w\") as outfile:\n",
    "    json.dump(country_dict, outfile, indent=4, separators=(\", \", \": \"))\n",
    "\n",
    "with open(f\"{filepath}/data_json/regions.json\", \"w\") as outfile:\n",
    "    json.dump(region_dict, outfile, indent=4, separators=(\", \", \": \"))\n",
    "\n",
    "with open(f\"{filepath}/data_json/spending_pop.json\", \"w\") as outfile:\n",
    "    json.dump(spending_dict, outfile, indent=4, separators=(\", \", \": \"))\n",
    "\n",
    "with open(f\"{filepath}/data_json/amr.json\", \"w\") as outfile:\n",
    "    json.dump(amr_dict, outfile, indent=4, separators=(\", \", \": \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
